{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import quantus\n",
    "\n",
    "from xai_methods import RELAX, LaFAM, GradCAMHeatmap\n",
    "from utils import *\n",
    "\n",
    "def choose_device() -> str:\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda:0\"\n",
    "    if hasattr(torch.backends, \"mps\"):\n",
    "        if torch.backends.mps.is_available():\n",
    "            return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "device = torch.device(choose_device())\n",
    "print(torch.cuda.get_device_name(device))\n",
    "\n",
    "# fix seed for reproducibility\n",
    "seed = 123\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed) # multi-GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        SquareCropAndResize(224),\n",
    "        torchvision.transforms.ToTensor(),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "inverse_transform = torchvision.transforms.Compose(\n",
    "    [\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[0.0, 0.0, 0.0], std=[1 / 0.229, 1 / 0.224, 1 / 0.225]\n",
    "        ),\n",
    "        torchvision.transforms.Normalize(\n",
    "            mean=[-0.485, -0.456, -0.406], std=[1.0, 1.0, 1.0]\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "quantus_metrics = [\n",
    "    quantus.PointingGame,\n",
    "    quantus.TopKIntersection,\n",
    "    quantus.Sparseness,\n",
    "    quantus.AUC,\n",
    "    quantus.AttributionLocalisation,\n",
    "    quantus.RelevanceRankAccuracy,\n",
    "    quantus.RelevanceMassAccuracy,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet50(weights=\"ResNet50_Weights.IMAGENET1K_V1\")\n",
    "# resnet = torchvision.models.resnet50(pretrained=True)\n",
    "resnet.eval().to(device)\n",
    "\n",
    "layer_idx = get_layer_idx(resnet, resnet.layer4)\n",
    "# print(\"Layer index: \", layer_idx)\n",
    "\n",
    "# Take only CCN layers\n",
    "resnet_layer4 = torch.nn.Sequential(*list(resnet.children())[: layer_idx + 1])\n",
    "resnet_layer4.eval();\n",
    "# list(resnet_layer4.children())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pl_bolts.models.self_supervised import SimCLR, SwAV\n",
    "\n",
    "\n",
    "simclr = (\n",
    "    SimCLR.load_from_checkpoint(\n",
    "        \"https://pl-bolts-weights.s3.us-east-2.amazonaws.com/simclr/bolts_simclr_imagenet/simclr_imagenet.ckpt\",\n",
    "        strict=False,\n",
    "    )\n",
    "    .encoder.eval()\n",
    "    .to(device)\n",
    ")\n",
    "layer_idx = get_layer_idx(simclr, simclr.layer4)\n",
    "simclr_layer4 = torch.nn.Sequential(*list(simclr.children())[: layer_idx + 1])\n",
    "simclr_layer4.eval().to(device)\n",
    "\n",
    "swav = (\n",
    "    SwAV.load_from_checkpoint(\n",
    "        \"https://pl-bolts-weights.s3.us-east-2.amazonaws.com/swav/bolts_swav_imagenet/swav_imagenet.ckpt\",\n",
    "        strict=False,\n",
    "    )\n",
    "    .model\n",
    "    .eval()\n",
    "    .to(device)\n",
    ")\n",
    "layer_idx = get_layer_idx(swav, swav.layer4)\n",
    "swav_layer4 = torch.nn.Sequential(*list(swav.children())[: layer_idx + 1])\n",
    "swav_layer4.eval().to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ImageNet-1k + ImageNet-S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the dataset is gated/private, make sure you have run huggingface-cli login\n",
    "imgent_ds = load_dataset(\"imagenet-1k\", streaming=False, split=\"validation\")\n",
    "\n",
    "imgnet_labels = imgent_ds._info.features[\"label\"].names\n",
    "\n",
    "len(imgent_ds), len(imgnet_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert huggingface dataset to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for i, (img, l) in enumerate(zip(imgent_ds._data[\"image\"], imgent_ds._data[\"label\"])):\n",
    "    l = l.as_py()\n",
    "    path = img[\"path\"].as_py()\n",
    "    row = {}\n",
    "    row[\"category\"] = path.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]\n",
    "    row[\"filename\"] = path.split(\"/\")[-1].split(\"_n\")[0]\n",
    "    row[\"label_names\"] = imgnet_labels[l]\n",
    "    row[\"label\"] = l\n",
    "    row[\"dataset_idx\"] = i\n",
    "    rows.append(row)\n",
    "\n",
    "# set dtype int instead of numpy.int64\n",
    "imgent_df = pd.DataFrame(rows)\n",
    "del rows\n",
    "imgent_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map ImageNet-1k to ImageNet-S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "file_paths = glob.glob(\"../../ImageNetS919/validation-segmentation/*/*\")\n",
    "imgnet_s_path = [path.split(\"/\")[-1].split(\".\")[0] for path in file_paths]\n",
    "print(len(file_paths), len(imgnet_s_path))\n",
    "imgnet_s_path[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match names and dataframe\n",
    "imgnet_s_df = imgent_df[imgent_df[\"filename\"].isin(imgnet_s_path)].copy()\n",
    "# match file_paths and df_seg['filename']\n",
    "imgnet_s_df[\"file_path\"] = imgnet_s_df[\"filename\"].apply(\n",
    "    lambda x: file_paths[imgnet_s_path.index(x)]\n",
    ")\n",
    "\n",
    "print(len(imgnet_s_df))\n",
    "imgnet_s_df[['filename', 'file_path']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/LUSSeg/ImageNet-S?tab=readme-ov-file#qa\n",
    "def get_seg_id(path):\n",
    "    segmentation = Image.open(path)  # RGB\n",
    "    segmentation = np.array(segmentation)\n",
    "    seg = segmentation[:, :, 1] * 256 + segmentation[:, :, 0]  # R+G*256\n",
    "    seg = np.unique(seg)\n",
    "    seg = seg[(seg != 0) & (seg != 1000)]\n",
    "    return seg\n",
    "\n",
    "\n",
    "imgnet_s_df[\"segmentation_id\"] = imgnet_s_df[\"file_path\"].apply(lambda x: get_seg_id(x))\n",
    "imgnet_s_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgnet_s_df = imgnet_s_df[imgnet_s_df[\"segmentation_id\"].apply(lambda x: len(x)) > 1].copy()\n",
    "print(len(imgnet_s_df))\n",
    "imgnet_s_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_methods = (\n",
    "    (\"ResNet LaFAM\", LaFAM(resnet_layer4, interpolation=\"nearest\", threshold=None)),\n",
    "    (\"SimCLR LaFAM\", LaFAM(simclr_layer4, interpolation=\"nearest\", threshold=None)),\n",
    "    (\n",
    "        \"SimCLR RELAX\",\n",
    "        RELAX(\n",
    "            simclr,\n",
    "            n_masks=2048,\n",
    "            n_cells=7,\n",
    "            occlusion_batch_size=1024,\n",
    "            threshold=None,\n",
    "            unpack_output=lambda x: x[0], # unpack output from SimCLR\n",
    "            device=device,\n",
    "            mask_interpolation=\"nearest\",\n",
    "            heatmap_interpolation=\"nearest\",\n",
    "        ),\n",
    "    ),\n",
    "    (\"SwAV LaFAM\", LaFAM(swav_layer4, interpolation=\"nearest\", threshold=None)),\n",
    "    (\n",
    "        \"SwAV RELAX\",\n",
    "        RELAX(\n",
    "            swav,\n",
    "            n_masks=2048,\n",
    "            n_cells=7,\n",
    "            occlusion_batch_size=1024,\n",
    "            threshold=None,\n",
    "            unpack_output=lambda x: x[0],\n",
    "            device=device,\n",
    "            mask_interpolation=\"nearest\",\n",
    "            heatmap_interpolation=\"nearest\",\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "gradcam_heatmap = GradCAMHeatmap(\n",
    "    resnet, resnet.layer4, imgnet_labels, interpolation=\"nearest\", threshold=None\n",
    ")\n",
    "\n",
    "target_transform = SquareCropAndResize(224, interpolation=Image.NEAREST)\n",
    "\n",
    "results = []\n",
    "\n",
    "for _, row in tqdm(imgnet_s_df.iterrows(), total=len(imgnet_s_df)):\n",
    "    ds_idx = int(row[\"dataset_idx\"])\n",
    "\n",
    "    img = imgent_ds[ds_idx][\"image\"]\n",
    "    img = imagenet_transform(img.convert(\"RGB\"))\n",
    "    x_batch = img.to(device).unsqueeze(0)\n",
    "\n",
    "    seg = Image.open(row[\"file_path\"])\n",
    "    seg = target_transform(seg)\n",
    "    seg = np.array(seg)\n",
    "    seg = seg[:, :, 1] * 256 + seg[:, :, 0]\n",
    "\n",
    "    m = seg.max()\n",
    "    mask = torch.zeros(seg.shape)\n",
    "    mask[seg == m] = 1\n",
    "    s_batch = mask.unsqueeze(0)\n",
    "\n",
    "    start = time.time()\n",
    "    a_batch, pred_label = gradcam_heatmap(x_batch)\n",
    "    total_time = time.time() - start\n",
    "\n",
    "    result = {\n",
    "        \"dataset_idx\": ds_idx,\n",
    "        \"total_time\": total_time,\n",
    "        \"prediction\": pred_label,\n",
    "        \"labels\": row[\"label_names\"],\n",
    "        \"xai_method\": \"ResNet Grad-CAM\",\n",
    "    }\n",
    "\n",
    "    result.update(evaluate(x_batch, s_batch, a_batch.detach(), quantus_metrics, device))\n",
    "    results.append(result)\n",
    "\n",
    "    for method_info in xai_methods:\n",
    "        name, xai_method = method_info\n",
    "\n",
    "        start = time.time()\n",
    "        a_batch = xai_method(x_batch, silent=True)\n",
    "        total_time = time.time() - start\n",
    "\n",
    "        result = {\n",
    "            \"dataset_idx\": ds_idx,\n",
    "            \"total_time\": total_time,\n",
    "            \"prediction\": pred_label,\n",
    "            \"labels\": row[\"label_names\"],\n",
    "            \"xai_method\": name,\n",
    "        }\n",
    "\n",
    "        r = evaluate(x_batch, s_batch, a_batch, quantus_metrics, device)\n",
    "        result.update(r)\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [metric.name for metric in quantus_metrics]\n",
    "cols.append(\"total_time\")\n",
    "cols.append(\"xai_method\")\n",
    "results_df[cols].groupby(\"xai_method\").mean().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PASCAL Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_labels = {\n",
    "    1: \"aeroplane\",\n",
    "    2: \"bicycle\",\n",
    "    3: \"bird\",\n",
    "    4: \"boat\",\n",
    "    5: \"bottle\",\n",
    "    6: \"bus\",\n",
    "    7: \"car\",\n",
    "    8: \"cat\",\n",
    "    9: \"chair\",\n",
    "    10: \"cow\",\n",
    "    11: \"diningtable\",\n",
    "    12: \"dog\",\n",
    "    13: \"horse\",\n",
    "    14: \"motorbike\",\n",
    "    15: \"person\",\n",
    "    16: \"potted plant\",\n",
    "    17: \"sheep\",\n",
    "    18: \"sofa\",\n",
    "    19: \"train\",\n",
    "    20: \"tv/monitor\",\n",
    "}\n",
    "\n",
    "\n",
    "pascal_ds = torchvision.datasets.VOCSegmentation(\n",
    "    root=\"../data/VOCdevkit\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"val\",\n",
    "    download=False,\n",
    "    transform=imagenet_transform,\n",
    "    target_transform=SquareCropAndResize(224, interpolation=Image.NEAREST),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labels from json file\n",
    "with open(\"imagenet_class_index.json\") as f:\n",
    "    imagenet_labels = list(json.load(f).values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pandas dataframe from torch dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for idx, (_, mask) in enumerate(pascal_ds):\n",
    "    mask = np.array(mask)\n",
    "    labels = np.unique(mask)\n",
    "    labels = labels[(labels != 0) & (labels != 255)]\n",
    "\n",
    "    data.append(\n",
    "        {\n",
    "            \"dataset_idx\": idx,\n",
    "            \"labels\": labels,\n",
    "            \"label_count\": len(labels),\n",
    "            \"label_names\": [pascal_labels[label] for label in labels],\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create a pandas dataframe\n",
    "pascal_df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "print(f\"Number of images: {len(pascal_df)}\")\n",
    "\n",
    "pascal_df[\"label_names\"].explode().value_counts().plot(\n",
    "    kind=\"bar\", figsize=(6, 3), title=\"Pascal VOC 2012 - labels distribution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pascal_df = pascal_df[pascal_df[\"label_count\"] == 1].copy()\n",
    "\n",
    "exclude_classes = [\n",
    "    \"person\",\n",
    "    \"tv/monitor\",\n",
    "    \"sofa\",\n",
    "    \"potted plant\",\n",
    "    \"diningtable\",\n",
    "    \"chair\",\n",
    "    \"bottle\",\n",
    "]\n",
    "pascal_df = pascal_df[\n",
    "    ~pascal_df[\"label_names\"].apply(lambda x: any(cls in x for cls in exclude_classes))\n",
    "].copy()\n",
    "\n",
    "print(f\"Number of images: {len(pascal_df)}\")\n",
    "\n",
    "pascal_df[\"label_names\"].explode().value_counts().plot(\n",
    "    kind=\"bar\", figsize=(6, 3), title=\"Pascal VOC 2012 - labels distribution\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch dataset wrapper for pandas dataframe\n",
    "class PascalVOC2012Seg(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, ds):\n",
    "        self.df = df\n",
    "        self.ds = ds\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get df row\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img, seg = self.ds[row.dataset_idx]\n",
    "\n",
    "        seg = torch.tensor(np.array(seg))\n",
    "\n",
    "        # remove outline\n",
    "        seg[seg == 255] = 0\n",
    "        seg[seg > 0] = 1\n",
    "\n",
    "        return img, seg, row.to_dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "pasvoc2012_seg = PascalVOC2012Seg(pascal_df, pascal_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xai_methods = (\n",
    "    (\"ResNet LaFAM\", LaFAM(resnet_layer4, interpolation=\"nearest\", threshold=None)),\n",
    "    (\"SimCLR LaFAM\", LaFAM(simclr_layer4, interpolation=\"nearest\", threshold=None)),\n",
    "    (\n",
    "        \"SimCLR RELAX\",\n",
    "        RELAX(\n",
    "            simclr,\n",
    "            n_masks=2048,\n",
    "            n_cells=7,\n",
    "            occlusion_batch_size=1024,\n",
    "            threshold=None,\n",
    "            unpack_output=lambda x: x[0],\n",
    "            device=device,\n",
    "            mask_interpolation=\"nearest\",\n",
    "            heatmap_interpolation=\"nearest\",\n",
    "        ),\n",
    "    ),\n",
    "    (\"SwAV LaFAM\", LaFAM(swav_layer4, interpolation=\"nearest\", threshold=None)),\n",
    "    (\n",
    "        \"SwAV RELAX\",\n",
    "        RELAX(\n",
    "            swav,\n",
    "            n_masks=2048,\n",
    "            n_cells=7,\n",
    "            occlusion_batch_size=1024,\n",
    "            threshold=None,\n",
    "            unpack_output=lambda x: x[0],\n",
    "            device=device,\n",
    "            mask_interpolation=\"nearest\",\n",
    "            heatmap_interpolation=\"nearest\",\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "gradcam_heatmap = GradCAMHeatmap(\n",
    "    resnet, resnet.layer4, imagenet_labels, interpolation=\"nearest\", threshold=None\n",
    ")\n",
    "\n",
    "results = []\n",
    "\n",
    "for batch in tqdm(torch.utils.data.DataLoader(pasvoc2012_seg, batch_size=1)):\n",
    "    x_batch = batch[0].to(device)\n",
    "    s_batch = batch[1]\n",
    "    row = batch[2]\n",
    "\n",
    "    ds_idx = row[\"dataset_idx\"].item()\n",
    "\n",
    "    start = time.time()\n",
    "    a_batch, pred_label = gradcam_heatmap(x_batch)\n",
    "    total_time = time.time() - start\n",
    "\n",
    "    result = {\n",
    "        \"dataset_idx\": ds_idx,\n",
    "        \"total_time\": total_time,\n",
    "        \"prediction\": pred_label,\n",
    "        \"labels\": row[\"label_names\"][0],\n",
    "        \"xai_method\": \"ResNet Grad-CAM\",\n",
    "    }\n",
    "\n",
    "    result.update(evaluate(x_batch, s_batch, a_batch.detach(), quantus_metrics, device))\n",
    "    results.append(result)\n",
    "\n",
    "    for method_info in xai_methods:\n",
    "        name, xai_method = method_info\n",
    "\n",
    "        start = time.time()\n",
    "        a_batch = xai_method(x_batch, silent=True)\n",
    "        total_time = time.time() - start\n",
    "\n",
    "        result = {\n",
    "            \"dataset_idx\": ds_idx,\n",
    "            \"total_time\": total_time,\n",
    "            \"prediction\": pred_label,\n",
    "            \"labels\": row[\"label_names\"][0],\n",
    "            \"xai_method\": name,\n",
    "        }\n",
    "\n",
    "        r = evaluate(x_batch, s_batch, a_batch, quantus_metrics, device)\n",
    "        result.update(r)\n",
    "        results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "results_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [metric.name for metric in quantus_metrics]\n",
    "cols.append(\"total_time\")\n",
    "cols.append(\"xai_method\")\n",
    "results_df[cols].groupby(\"xai_method\").mean().T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
